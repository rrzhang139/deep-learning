"Efficient Large-scale Stereo Matching" by Heiko Hirschmüller (2005)

Introduced the Semi-Global Matching (SGM) algorithm, which became a popular choice for stereo matching and 3D reconstruction due to its efficiency and accuracy.
Foundational work in stereo-based 3D reconstruction.


"Kinect Fusion: Real-time Dense Surface Mapping and Tracking" by Richard A. Newcombe, Shahram Izadi, Otmar Hilliges, and David Molyneaux (2011)

Presented a real-time 3D reconstruction system that combines depth data from a Kinect sensor with a volumetric representation to create dense 3D models of indoor scenes.
Demonstrated the potential of real-time 3D reconstruction using consumer-grade depth sensors.

"Structure from Motion Revisited" by Johannes L. Schönberger and Jan-Michael Frahm (2016)

Provided a comprehensive review and analysis of Structure from Motion (SfM) techniques for 3D reconstruction from multiple images.
Consolidated and advanced the understanding of SfM techniques, serving as a valuable resource for researchers and practitioners.


"Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling" by Jiajun Wu, Chengkai Zhang, Tianfan Xue, Bill Freeman, and Josh Tenenbaum (2016)

Introduced the 3D-GAN architecture for generating 3D shapes using generative adversarial networks (GANs).
Pioneered the use of deep learning techniques for 3D shape generation and opened up new possibilities for learning-based 3D modeling.


"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation" by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas (2017)

Introduced PointNet, a deep learning architecture for directly processing point cloud data for 3D classification and segmentation tasks.
Revolutionized the way deep learning is applied to 3D point cloud data and inspired numerous follow-up works.


"Occupancy Networks: Learning 3D Reconstruction in Function Space" by Lars Mescheder, Michael Oechsle, Michael Niemeyer, Sebastian Nowozin, and Andreas Geiger (2019)

Proposed Occupancy Networks, a deep learning approach for 3D reconstruction that learns a continuous occupancy function to represent 3D shapes.
Introduced a novel way of representing 3D shapes using learned occupancy functions, enabling high-quality 3D reconstruction from various input modalities.


"DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation" by Jeong Joon Park, Peter Florence, Julian Straub, Richard Newcombe, and Steven Lovegrove (2019)

Introduced DeepSDF, a deep learning approach for representing 3D shapes using continuous signed distance functions (SDFs) learned from point clouds.
Advanced the field of learning-based 3D shape representation and reconstruction using implicit functions.


"Mesh R-CNN" by Georgia Gkioxari, Jitendra Malik, and Justin Johnson (2019)

Presented Mesh R-CNN, a deep learning framework for generating 3D meshes from single RGB images by combining convolutional neural networks (CNNs) and graph convolutional networks (GCNs).
Demonstrated the potential of end-to-end learning for 3D mesh generation from 2D images.


"NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis" by Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi, and Ren Ng (2020)

Presented NeRF, a neural rendering approach that represents scenes as neural radiance fields for high-quality view synthesis and 3D reconstruction.
Introduced a paradigm shift in 3D scene representation and rendering using neural networks, achieving state-of-the-art results in novel view synthesis and spurring a new line of research in neural rendering.